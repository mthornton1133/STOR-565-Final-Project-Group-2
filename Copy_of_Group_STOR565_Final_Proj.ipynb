{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKHuNSLKENpY"
      },
      "source": [
        "# Bag of Visual Words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8GbEAD46EnZa"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from google.colab import files\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "from sklearn.cluster import MiniBatchKMeans, KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import normalize, StandardScaler\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, roc_auc_score, roc_curve\n",
        "from sklearn.manifold import TSNE\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gXbqLY_Ie8J7"
      },
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"andrewmvd/isic-2019\")\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VKmYNLIJe_xf"
      },
      "outputs": [],
      "source": [
        "metadata_path = os.path.join(path, \"ISIC_2019_Training_Metadata.csv\")\n",
        "labels_path = os.path.join(path, \"ISIC_2019_Training_GroundTruth.csv\")\n",
        "metadata_df = pd.read_csv(\"/root/.cache/kagglehub/datasets/andrewmvd/isic-2019/versions/1/ISIC_2019_Training_Metadata.csv\")\n",
        "labels_df = pd.read_csv(labels_path)\n",
        "# View the first few rows\n",
        "print(metadata_df.head())\n",
        "print(labels_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I06rHWVsgOmy"
      },
      "outputs": [],
      "source": [
        "image_ids = labels_df['image'].values\n",
        "image_path = os.path.join(path, \"ISIC_2019_Training_Input\", \"ISIC_2019_Training_Input\", image_ids[1] + \".jpg\")\n",
        "image = Image.open(image_path)\n",
        "image_np = np.array(image)\n",
        "print(\"Image shape:\", image_np.shape)\n",
        "plt.imshow(image)\n",
        "plt.axis('off')\n",
        "plt.title(image_ids[1])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CzfIQ5jmfDPe"
      },
      "outputs": [],
      "source": [
        "extractor = cv2.ORB_create()\n",
        "#extractor = cv2.SIFT_create()\n",
        "descriptors_all = []\n",
        "used_image_id_all = []\n",
        "keypoints_all = []\n",
        "for image_id in tqdm(image_ids):\n",
        "    image_path = os.path.join(path, \"ISIC_2019_Training_Input\", \"ISIC_2019_Training_Input\", image_id + \".jpg\")\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        continue\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    keypoint, descriptor = extractor.detectAndCompute(gray, None)\n",
        "    if descriptors_all is not None:\n",
        "        descriptors_all.append(descriptor)\n",
        "        used_image_id_all.append(image_id)\n",
        "    keypoints_all.append(keypoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "86QUGUgifOYD"
      },
      "outputs": [],
      "source": [
        "labels_df_filtered_a = labels_df[labels_df['image'].isin(used_image_id_all)].copy()\n",
        "labels_df_filtered_all = labels_df_filtered_a.set_index(\"image\").loc[used_image_id_all]\n",
        "y_all = labels_df_filtered_all[\"MEL\"].values.astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "644LoiS0gDjo"
      },
      "outputs": [],
      "source": [
        "out_dir = os.path.expanduser(\"~/plots\")\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "first_image_path = os.path.join(path, \"ISIC_2019_Training_Input\", \"ISIC_2019_Training_Input\", image_ids[1] + \".jpg\")\n",
        "image = Image.open(first_image_path)\n",
        "image_np = np.array(image)\n",
        "output_image = cv2.drawKeypoints(image_np, keypoints_all[0], 0, (255, 0, 0), flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
        "plt.imshow(output_image)\n",
        "image_file = os.path.join(out_dir, \"image0.png\")\n",
        "plt.savefig(image_file, bbox_inches=\"tight\")\n",
        "plt.show()\n",
        "\n",
        "files.download(image_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mor4FIa1fSkZ"
      },
      "outputs": [],
      "source": [
        "descriptor_list_all = []\n",
        "for img_des in descriptors_all:\n",
        "    if img_des is not None:\n",
        "        descriptor_list_all.extend(img_des)\n",
        "all_descriptors_all = np.vstack(descriptor_list_all)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9sazn1lyfVZn"
      },
      "outputs": [],
      "source": [
        "kmeans_all = MiniBatchKMeans(n_clusters=100, batch_size=100000)\n",
        "kmeans_all.fit(all_descriptors_all)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KuliraBuldis"
      },
      "outputs": [],
      "source": [
        "def build_bovw_histogram(descriptors, kmeans_model, k):\n",
        "    histogram = np.zeros(k)\n",
        "    if descriptors is not None:\n",
        "        cluster_result = kmeans_all.predict(descriptors)\n",
        "        for i in cluster_result:\n",
        "            histogram[i] += 1\n",
        "    return histogram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aAiz9a8AffvB"
      },
      "outputs": [],
      "source": [
        "bovw_features_all = []\n",
        "for img_des in tqdm(descriptors_all):\n",
        "    hist = build_bovw_histogram(img_des, kmeans_all, 100)\n",
        "    bovw_features_all.append(hist)\n",
        "bovw_features_all = np.array(bovw_features_all)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0qx2FH8LfhzJ"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "X_scaled_all = scaler.fit_transform(bovw_features_all)\n",
        "X_train_all, X_test_all, y_train_all, y_test_all = train_test_split(X_scaled_all, y_all, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qUExEop4fiNh"
      },
      "outputs": [],
      "source": [
        "lg = LogisticRegression()\n",
        "lg.fit(X_train_all, y_train_all)\n",
        "print(lg.score(X_test_all, y_test_all))\n",
        "kneighbors = KNeighborsClassifier()\n",
        "kneighbors.fit(X_train_all, y_train_all)\n",
        "print(kneighbors.score(X_test_all, y_test_all))\n",
        "linear_svm = SVC(kernel='linear')\n",
        "linear_svm.fit(X_train_all, y_train_all)\n",
        "print(linear_svm.score(X_test_all, y_test_all))\n",
        "gauss_svm = SVC(kernel='rbf')\n",
        "gauss_svm.fit(X_train_all, y_train_all)\n",
        "print(gauss_svm.score(X_test_all, y_test_all))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7DDQIyHER8E"
      },
      "source": [
        "# PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1NNxG5nxEoSK"
      },
      "outputs": [],
      "source": [
        "labels_path = os.path.join(path, \"ISIC_2019_Training_GroundTruth.csv\")\n",
        "labels_df = pd.read_csv(labels_path)\n",
        "labels_df[\"image\"] = labels_df[\"image\"].astype(str)\n",
        "\n",
        "# Prepare image file list\n",
        "nested_folder = os.path.join(path, \"ISIC_2019_Training_Input\")\n",
        "image_folder = os.path.join(nested_folder, \"ISIC_2019_Training_Input\")\n",
        "if not os.path.exists(image_folder):\n",
        "    image_folder = nested_folder\n",
        "\n",
        "image_files = [\n",
        "    os.path.join(image_folder, f)\n",
        "    for f in os.listdir(image_folder)\n",
        "    if f.lower().endswith(('.jpg', '.jpeg', '.png'))\n",
        "]\n",
        "\n",
        "print(\"Total images found:\", len(image_files))\n",
        "\n",
        "# Map to cancerous label\n",
        "cancerous_cols = [\"MEL\", \"BCC\", \"SCC\"]\n",
        "labels_df[\"cancerous\"] = labels_df[cancerous_cols].max(axis=1)\n",
        "\n",
        "def get_image_id(path):\n",
        "    return os.path.splitext(os.path.basename(path))[0]\n",
        "\n",
        "# Build labels array\n",
        "labels = []\n",
        "valid_files = []\n",
        "for f in image_files:\n",
        "    img_id = get_image_id(f)\n",
        "    row = labels_df[labels_df[\"image\"] == img_id]\n",
        "    if len(row):\n",
        "        labels.append(int(row[\"cancerous\"].values[0]))\n",
        "        valid_files.append(f)\n",
        "labels = np.array(labels)\n",
        "image_files = valid_files\n",
        "\n",
        "print(\"Images with labels:\", len(image_files))\n",
        "print(\"Class distribution:\", np.bincount(labels))\n",
        "\n",
        "image_files, _, labels, _ = train_test_split(\n",
        "     image_files, labels,\n",
        "     train_size=2000,\n",
        "     stratify=labels,\n",
        "     random_state=42\n",
        ")\n",
        "print(\"After sampling:\", len(image_files), \"images\")\n",
        "\n",
        "# Improved SIFT configuration\n",
        "sift = cv2.SIFT_create(contrastThreshold=0.005, edgeThreshold=20)\n",
        "MAX_DESC = 1000  # increase cap\n",
        "\n",
        "def process_image(path, target_size=(300,300)):\n",
        "    img = cv2.imread(path)\n",
        "    if img is None: return None\n",
        "    img = cv2.resize(img, target_size)\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    _, descriptors = sift.detectAndCompute(gray, None)\n",
        "    if descriptors is not None and descriptors.shape[0] > MAX_DESC:\n",
        "        idx = np.random.choice(descriptors.shape[0], MAX_DESC, replace=False)\n",
        "        descriptors = descriptors[idx]\n",
        "    return descriptors\n",
        "\n",
        "# Extract descriptors\n",
        "all_desc = []\n",
        "with ThreadPoolExecutor(max_workers=8) as ex:\n",
        "    futures = {ex.submit(process_image, f): f for f in image_files}\n",
        "    for future in tqdm(as_completed(futures), total=len(futures)):\n",
        "        d = future.result()\n",
        "        if d is not None and d.size>0:\n",
        "            all_desc.append(d)\n",
        "all_desc = np.vstack(all_desc)\n",
        "print(\"Total SIFT descriptors:\", all_desc.shape)\n",
        "\n",
        "# PCA + whitening\n",
        "pca = PCA(n_components=64, whiten=True)\n",
        "desc_red = pca.fit_transform(all_desc)\n",
        "print(\"Descriptors after PCA:\", desc_red.shape)\n",
        "\n",
        "# KMeans codebook\n",
        "num_clusters = 128\n",
        "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
        "kmeans.fit(desc_red)\n",
        "\n",
        "# Soft-assignment histogram builder\n",
        "from sklearn.metrics import pairwise_distances\n",
        "def build_hist(path, top_k=3):\n",
        "    desc = process_image(path)\n",
        "    if desc is None or desc.size==0:\n",
        "        return np.zeros(num_clusters)\n",
        "    desc_r = pca.transform(desc)\n",
        "    dists = pairwise_distances(desc_r, kmeans.cluster_centers_)\n",
        "    h = np.zeros(num_clusters)\n",
        "    for row in dists:\n",
        "        nn = np.argsort(row)[:top_k]\n",
        "        w = 1/(row[nn]+1e-6)\n",
        "        w /= w.sum()\n",
        "        h[nn] += w\n",
        "    return h\n",
        "\n",
        "# Build histograms\n",
        "hists = []\n",
        "with ThreadPoolExecutor(max_workers=8) as ex:\n",
        "    futures = {ex.submit(build_hist, f): f for f in image_files}\n",
        "    for future in tqdm(as_completed(futures), total=len(futures)):\n",
        "        hists.append(future.result())\n",
        "hists = np.array(hists)\n",
        "\n",
        "# Normalize & scale\n",
        "h_norm = normalize(hists, norm='l1', axis=1)\n",
        "scaler = StandardScaler()\n",
        "h_scaled = scaler.fit_transform(h_norm)\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    h_scaled, labels, test_size=0.2, stratify=labels, random_state=100\n",
        ")\n",
        "\n",
        "# Classifiers\n",
        "clfs = {\n",
        "    \"SVM\": SVC(kernel='linear', probability=True, random_state=100),\n",
        "    \"KNN\": KNeighborsClassifier(),\n",
        "    \"LogReg\": LogisticRegression(max_iter=1000, random_state=100)\n",
        "}\n",
        "\n",
        "for name, clf in clfs.items():\n",
        "    clf.fit(X_train, y_train)\n",
        "    yp = clf.predict(X_test)\n",
        "    print(f\"\\n{name} accuracy:\", accuracy_score(y_test, yp))\n",
        "    print(classification_report(y_test, yp))\n",
        "    cv = cross_val_score(clf, h_scaled, labels, cv=5, n_jobs=-1)\n",
        "    print(f\"{name} CV acc: {cv.mean():.3f}±{cv.std():.3f}\")\n",
        "    prob = clf.predict_proba(X_test)[:,1]\n",
        "    print(f\"{name} ROC-AUC:\", roc_auc_score(y_test, prob))\n",
        "\n",
        "# t‑SNE for ORB\n",
        "tsne_orb = TSNE(n_components=2, random_state=100, perplexity=30, n_iter=1000)\n",
        "orb_tsne = tsne_orb.fit_transform(X_scaled_all)\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(orb_tsne[:, 0], orb_tsne[:, 1], s=30, c=y_all, cmap='coolwarm', alpha=0.7)\n",
        "plt.title(\"t‑SNE of ORB-based BoVW Features\")\n",
        "plt.xlabel(\"Component 1\")\n",
        "plt.ylabel(\"Component 2\")\n",
        "plt.colorbar(label=\"Cancerous (1) vs Non-Cancerous (0)\")\n",
        "plt.show()\n",
        "\n",
        "# Confusion Matrix for ORB SVM\n",
        "y_pred_orb = linear_svm.predict(X_test_all)\n",
        "cm_orb = confusion_matrix(y_test_all, y_pred_orb)\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm_orb, annot=True, fmt=\"d\", cmap='Blues', cbar=False)\n",
        "plt.title(\"Confusion Matrix — ORB-based Linear SVM\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.show()\n",
        "\n",
        "# t‑SNE for SIFT\n",
        "tsne_sift = TSNE(n_components=2, random_state=100, perplexity=30, n_iter=1000)\n",
        "hist_2d_tsne = tsne_sift.fit_transform(hist_array_scaled)\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(hist_2d_tsne[:, 0], hist_2d_tsne[:, 1], s=30, c=labels, cmap='coolwarm', alpha=0.7)\n",
        "plt.title(\"t‑SNE of SIFT-based BoVW Features\")\n",
        "plt.xlabel(\"Component 1\")\n",
        "plt.ylabel(\"Component 2\")\n",
        "plt.colorbar(label=\"Cancerous (1) vs Non-Cancerous (0)\")\n",
        "plt.show()\n",
        "\n",
        "# Confusion Matrix for SIFT SVM\n",
        "best_clf = classifiers[\"SVM\"]\n",
        "y_pred_best = best_clf.predict(X_test)\n",
        "cm_sift = confusion_matrix(y_test, y_pred_best)\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm_sift, annot=True, fmt=\"d\", cmap='Blues', cbar=False)\n",
        "plt.title(\"Confusion Matrix — SIFT-based Linear SVM\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w3R86AtDdrSZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from google.colab import files  # Import Colab file utilities\n",
        "\n",
        "# Define output directory (in Colab, work relative to /content)\n",
        "out_dir = os.path.expanduser(\"~/plots\")\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "# --------------------------\n",
        "# t‑SNE for ORB-based features\n",
        "# --------------------------\n",
        "tsne_orb = TSNE(n_components=2, random_state=42, perplexity=30, n_iter=1000)\n",
        "orb_tsne = tsne_orb.fit_transform(X_scaled_all)\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(orb_tsne[:, 0], orb_tsne[:, 1], s=30, c=y_all, cmap='coolwarm', alpha=0.7)\n",
        "plt.title(\"t‑SNE of ORB-based BoVW Features\")\n",
        "plt.xlabel(\"Component 1\")\n",
        "plt.ylabel(\"Component 2\")\n",
        "plt.colorbar(label=\"Cancerous (1) vs Non-Cancerous (0)\")\n",
        "orb_tsne_file = os.path.join(out_dir, \"tsne_orb.png\")\n",
        "plt.savefig(orb_tsne_file, bbox_inches=\"tight\")\n",
        "plt.show()\n",
        "\n",
        "# Download the ORB-based t‑SNE plot\n",
        "files.download(orb_tsne_file)\n",
        "\n",
        "# --------------------------\n",
        "# Confusion Matrix for ORB SVM\n",
        "# --------------------------\n",
        "y_pred_orb = linear_svm.predict(X_test_all)\n",
        "cm_orb = confusion_matrix(y_test_all, y_pred_orb)\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm_orb, annot=True, fmt=\"d\", cmap='Blues', cbar=False)\n",
        "plt.title(\"Confusion Matrix — ORB-based Linear SVM\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "confusion_orb_file = os.path.join(out_dir, \"confusion_orb_svm.png\")\n",
        "plt.savefig(confusion_orb_file, bbox_inches=\"tight\")\n",
        "plt.show()\n",
        "\n",
        "# Download the ORB SVM confusion matrix\n",
        "files.download(confusion_orb_file)\n",
        "\n",
        "# --------------------------\n",
        "# t‑SNE for SIFT-based features\n",
        "# --------------------------\n",
        "tsne_sift = TSNE(n_components=2, random_state=42, perplexity=30, n_iter=1000)\n",
        "hist_2d_tsne = tsne_sift.fit_transform(h_scaled)\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(hist_2d_tsne[:, 0], hist_2d_tsne[:, 1], s=30, c=labels, cmap='coolwarm', alpha=0.7)\n",
        "plt.title(\"t‑SNE of SIFT-based BoVW Features\")\n",
        "plt.xlabel(\"Component 1\")\n",
        "plt.ylabel(\"Component 2\")\n",
        "plt.colorbar(label=\"Cancerous (1) vs Non-Cancerous (0)\")\n",
        "tsne_sift_file = os.path.join(out_dir, \"tsne_sift.png\")\n",
        "plt.savefig(tsne_sift_file, bbox_inches=\"tight\")\n",
        "plt.show()\n",
        "\n",
        "# Download the SIFT-based t‑SNE plot\n",
        "files.download(tsne_sift_file)\n",
        "\n",
        "# --------------------------\n",
        "# Confusion Matrix for SIFT SVM\n",
        "# --------------------------\n",
        "best_clf = clfs[\"SVM\"]\n",
        "y_pred_best = best_clf.predict(X_test)\n",
        "cm_sift = confusion_matrix(y_test, y_pred_best)\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm_sift, annot=True, fmt=\"d\", cmap='Blues', cbar=False)\n",
        "plt.title(\"Confusion Matrix — SIFT-based Linear SVM\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "confusion_sift_file = os.path.join(out_dir, \"confusion_sift_svm.png\")\n",
        "plt.savefig(confusion_sift_file, bbox_inches=\"tight\")\n",
        "plt.show()\n",
        "\n",
        "# Download the SIFT SVM confusion matrix\n",
        "files.download(confusion_sift_file)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jVdKTnXEbyw"
      },
      "source": [
        "# CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7CMdMtviEouD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "#load original data\n",
        "original_groundtruth = pd.read_csv('/content/archive/ISIC_2019_Training_GroundTruth.csv')\n",
        "\n",
        "images_folder = '/content/archive/ISIC_2019_Training_Input/ISIC_2019_Training_Input'\n",
        "all_files = os.listdir(images_folder)\n",
        "images = []\n",
        "for file in all_files:\n",
        "    if file.endswith('.jpg'): #dodge txt files in dataset\n",
        "        images.append(file)\n",
        "\n",
        "paths = []\n",
        "for image in images:\n",
        "  paths.append(os.path.join(images_folder, image))\n",
        "\n",
        "original_groundtruth['class'] = 0\n",
        "\n",
        "cancerous = ['MEL','BCC','SCC']\n",
        "\n",
        "#assign class val 1 to all cancerous images\n",
        "original_groundtruth.loc[\n",
        "    (original_groundtruth['MEL'] == 1) | (original_groundtruth['BCC'] == 1) | (original_groundtruth['SCC'] == 1),\n",
        "    'class'] = 1\n",
        "\n",
        "#drop old label columns\n",
        "old_labels = ['MEL', 'NV', 'BCC', 'AK', 'BKL', 'DF', 'VASC', 'SCC', 'UNK']\n",
        "original_groundtruth = original_groundtruth.drop(columns=old_labels)\n",
        "original_groundtruth.rename(columns={'image': 'filename'}, inplace=True)\n",
        "original_groundtruth['filename'] = paths\n",
        "original_groundtruth['class'] = original_groundtruth['class'].astype(str) #str needed for tf/keras\n",
        "\n",
        "cancerous_images = original_groundtruth[original_groundtruth['class'] == '1']\n",
        "noncancerous_images = original_groundtruth[original_groundtruth['class'] == '0']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KV-IeLzfPkdt"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "cancer_images = groundtruth[groundtruth['class'] == '1']\n",
        "non_cancer_images = groundtruth[groundtruth['class'] == '0']\n",
        "\n",
        "print(len(cancer_images))\n",
        "print(len(non_cancer_images))\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "for i in range(5):\n",
        "    plt.subplot(1, 5, i + 1)\n",
        "    img = plt.imread(cancer_images.iloc[i]['filename'])\n",
        "    plt.imshow(img)\n",
        "    plt.title('Cancer')\n",
        "    plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "for i in range(5):\n",
        "    plt.subplot(1, 5, i + 1)\n",
        "    img = plt.imread(non_cancer_images.iloc[i]['filename'])\n",
        "    plt.imshow(img)\n",
        "    plt.title('Non-Cancer')\n",
        "    plt.axis('off')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uePRrZ8PPwfS"
      },
      "outputs": [],
      "source": [
        "import cv2 as cv\n",
        "\n",
        "#increase contrast in Y'UV colorspace for better border/color variation feature detection\n",
        "def up_contrast(image):\n",
        "  img = cv.imread(image)\n",
        "  img_yuv = cv.cvtColor(img, cv.COLOR_BGR2YUV)\n",
        "  img_yuv[:,:,0] = cv.equalizeHist(img_yuv[:,:,0])\n",
        "\n",
        "  img_output = cv.cvtColor(img_yuv, cv.COLOR_YUV2BGR)\n",
        "  return img_output\n",
        "\n",
        "#resize images for better training efficiency/ensure uniformity\n",
        "def resize(image):\n",
        "  img = cv.imread(image)\n",
        "  img = cv.resize(img, (224, 224))\n",
        "  return img\n",
        "\n",
        "for image in images:\n",
        "  img = resize(os.path.join(images_folder, image))\n",
        "  cv.imwrite(os.path.join(images_folder, image), img)\n",
        "\n",
        "for image in images:\n",
        "  img = up_contrast(os.path.join(images_folder, image))\n",
        "  cv.imwrite(os.path.join(images_folder, image), img)\n",
        "\n",
        "cancer_images2 = groundtruth[groundtruth['class'] == '1']\n",
        "non_cancer_images2 = groundtruth[groundtruth['class'] == '0']\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "for i in range(5):\n",
        "    plt.subplot(1, 5, i + 1)\n",
        "    img = plt.imread(cancer_images2.iloc[i]['filename'])\n",
        "    plt.imshow(img)\n",
        "    plt.title('Cancer')\n",
        "    plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "for i in range(5):\n",
        "    plt.subplot(1, 5, i + 1)\n",
        "    img = plt.imread(non_cancer_images2.iloc[i]['filename'])\n",
        "    plt.imshow(img)\n",
        "    plt.title('Non-Cancer')\n",
        "    plt.axis('off')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9kUAuUVP9LH"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df, val_df = train_test_split(groundtruth, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cVQw_hmrQCK4"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "#augment training images to mirror real-life variability in image data, randomized by epoch\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=15,\n",
        "    zoom_range=0.1,\n",
        "    width_shift_range=0.05,\n",
        "    height_shift_range=0.05,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    x_col='filename',\n",
        "    y_col='class',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    #subset='training',\n",
        "    #shuffle=True\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_dataframe(\n",
        "    dataframe=val_df,\n",
        "    x_col='filename',\n",
        "    y_col='class',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    #subset='validation',\n",
        "    #shuffle=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0MauDNYGQGLM"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "#naive CNN trained from scratch\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Flatten(),\n",
        "    Dropout(0.5),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tjdfCNcXQKuC"
      },
      "outputs": [],
      "source": [
        "\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=10\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0sXsOBycQOa5"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "y_true = val_generator.classes\n",
        "y_pred = np.round(model.predict(val_generator))\n",
        "\n",
        "precision = precision_score(y_true, y_pred)\n",
        "recall = recall_score(y_true, y_pred)\n",
        "f1 = f1_score(y_true, y_pred)\n",
        "\n",
        "print(classification_report(y_true, y_pred, target_names=['non-cancer', 'cancer']))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#New grayscale-based processing and transfer learning approach w/ ResNet50 model\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#load original data\n",
        "original_groundtruth = pd.read_csv('/content/archive/ISIC_2019_Training_GroundTruth.csv')\n",
        "\n",
        "images_folder = '/content/archive/ISIC_2019_Training_Input/ISIC_2019_Training_Input'\n",
        "all_files = os.listdir(images_folder)\n",
        "images = []\n",
        "for file in all_files:\n",
        "    if file.endswith('.jpg'): #dodge txt files in dataset\n",
        "        images.append(file)\n",
        "\n",
        "paths = []\n",
        "for image in images:\n",
        "  paths.append(os.path.join(images_folder, image))\n",
        "\n",
        "original_groundtruth['class'] = 0\n",
        "\n",
        "cancerous = ['MEL','BCC','SCC']\n",
        "\n",
        "#assign class val 1 to all cancerous images\n",
        "original_groundtruth.loc[\n",
        "    (original_groundtruth['MEL'] == 1) | (original_groundtruth['BCC'] == 1) | (original_groundtruth['SCC'] == 1),\n",
        "    'class'] = 1\n",
        "\n",
        "#drop old label columns\n",
        "old_labels = ['MEL', 'NV', 'BCC', 'AK', 'BKL', 'DF', 'VASC', 'SCC', 'UNK']\n",
        "original_groundtruth = original_groundtruth.drop(columns=old_labels)\n",
        "original_groundtruth.rename(columns={'image': 'filename'}, inplace=True)\n",
        "original_groundtruth['filename'] = paths\n",
        "original_groundtruth['class'] = original_groundtruth['class'].astype(str) #str needed for tf/keras\n",
        "\n",
        "cancerous_images = original_groundtruth[original_groundtruth['class'] == '1']\n",
        "noncancerous_images = original_groundtruth[original_groundtruth['class'] == '0']\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "for i in range(5):\n",
        "    plt.subplot(1, 5, i + 1)\n",
        "    img = plt.imread(original_groundtruth.iloc[i]['filename'])\n",
        "    plt.imshow(img)\n",
        "    plt.title('Original Imgs')\n",
        "    plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "for i in range(5):\n",
        "    plt.subplot(1, 5, i + 1)\n",
        "    img = plt.imread(original_groundtruth.iloc[i+5]['filename'])\n",
        "    plt.imshow(img)\n",
        "    plt.title('Original Imgs')\n",
        "    plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "print(len(original_groundtruth))\n",
        "print(len(cancerous_images))\n",
        "print(len(noncancerous_images))\n"
      ],
      "metadata": {
        "id": "cx6FjKMMdjeN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "#Preprocessing functions\n",
        "\n",
        "def preprocess_image(image_path):\n",
        "    #dull razor technique for hair removal from:\n",
        "    #https://github.com/BlueDokk/Dullrazor-algorithm/blob/main/dullrazor.py\n",
        "    image = cv2.imread(image_path)\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (9, 9))\n",
        "    blackhat = cv2.morphologyEx(gray, cv2.MORPH_BLACKHAT, kernel)\n",
        "    blur = cv2.GaussianBlur(blackhat, (3, 3), cv2.BORDER_REPLICATE)\n",
        "    _, mask = cv2.threshold(blur, 10, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "    inpainted = cv2.inpaint(gray, mask, 6, cv2.INPAINT_TELEA)\n",
        "    denoised = cv2.medianBlur(inpainted, ksize=5)\n",
        "    denoised = cv2.bilateralFilter(denoised, d=5, sigmaColor=25, sigmaSpace=25)\n",
        "    clahe = cv2.createCLAHE(clipLimit=1.5, tileGridSize=(8, 8))\n",
        "    s_gray = clahe.apply(denoised)\n",
        "    s_image = np.stack([s_gray] * 3, axis=-1)\n",
        "\n",
        "    #crop out black borders technique from:\n",
        "    #https://afetulhak.medium.com/crop-out-unwanted-border-pixels-from-medical-images-or-any-kind-of-image-b3def5dea2db\n",
        "    threshold = cv2.threshold(s_gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
        "    contours, _ = cv2.findContours(threshold, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
        "    if len(contours) == 0:\n",
        "      return cv2.resize(s_image, (224, 224))\n",
        "    x, y, w, h = cv2.boundingRect(contours[0])\n",
        "    sc_image = cv2.resize(s_image[y:y+h, x:x+w], (224, 224))\n",
        "\n",
        "    return sc_image"
      ],
      "metadata": {
        "id": "oRqJkBZ7eo95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\n",
        "\n",
        "dir = '/content/drive/MyDrive/dataset/preprocessed_images'\n",
        "os.makedirs(dir, exist_ok=True)\n",
        "\n",
        "preprocessed_images = []\n",
        "\n",
        "#apply random augmentations\n",
        "augment_image = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.05,\n",
        "    height_shift_range=0.05,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "for _, row in cancerous_images.iterrows():\n",
        "    path = row['filename']\n",
        "    label = row['class']\n",
        "\n",
        "    #apply preprocessing\n",
        "    pp_img = preprocess_image(path)\n",
        "    pp_img = pp_img.astype('float32') / 255.0\n",
        "    pp_img = pp_img.reshape((1,) + pp_img.shape)\n",
        "\n",
        "    for i, batch in enumerate(augment_image.flow(pp_img, batch_size=1, shuffle=False)):\n",
        "        base = os.path.basename(path).split('.')[0]\n",
        "        save_path = os.path.join(dir, f\"{base}_preprocessed{i}.jpg\")\n",
        "\n",
        "        array_to_img(batch[0]).save(save_path)\n",
        "        preprocessed_images.append({\n",
        "              'filename': save_path,\n",
        "              'class': '1'\n",
        "          })\n",
        "        if i == 1: #balance data by oversampling cancerous images 2:1 noncancerous\n",
        "          break\n",
        "\n",
        "for _, row in noncancerous_images.iterrows():\n",
        "    path = row['filename']\n",
        "    label = row['class']\n",
        "\n",
        "    #apply preprocessing\n",
        "    pp_img = preprocess_image(path)\n",
        "    pp_img = pp_img.astype('float32') / 255.0\n",
        "    pp_img = pp_img.reshape((1,) + pp_img.shape)\n",
        "\n",
        "    for j, batch in enumerate(augment_image.flow(pp_img, batch_size=1, shuffle=False)):\n",
        "        base = os.path.basename(path).split('.')[0]\n",
        "        save_path = os.path.join(dir, f\"{base}_preprocessed{j}.jpg\")\n",
        "\n",
        "        array_to_img(batch[0]).save(save_path)\n",
        "        preprocessed_images.append({\n",
        "          'filename': save_path,\n",
        "          'class': '0'\n",
        "\n",
        "        break\n",
        "\n",
        "preprocessed_groundtruth = pd.DataFrame(preprocessed_images)\n",
        "preprocessed_groundtruth.to_csv('/content/drive/MyDrive/preprocessed_groundtruth.csv', index=False)"
      ],
      "metadata": {
        "id": "WOoJrWN9e6lI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(preprocessed_groundtruth))\n",
        "\n",
        "preprocessed_cancerous_images = preprocessed_groundtruth[preprocessed_groundtruth['class'] == '1']\n",
        "preprocessed_noncancerous_images = preprocessed_groundtruth[preprocessed_groundtruth['class'] == '0']\n",
        "\n",
        "print(len(preprocessed_cancerous_images))\n",
        "print(len(preprocessed_noncancerous_images))\n",
        "\n",
        "random_canc_images = preprocessed_cancerous_images.sample(n=5)\n",
        "random_noncanc_images = preprocessed_noncancerous_images.sample(n=5)\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "for i in range(5):\n",
        "    plt.subplot(1, 5, i + 1)\n",
        "    img = plt.imread(random_canc_images.iloc[i]['filename'])\n",
        "    plt.imshow(img)\n",
        "    plt.title('Cancer Imgs')\n",
        "    plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "for i in range(5):\n",
        "    plt.subplot(1, 5, i + 1)\n",
        "    img = plt.imread(random_noncanc_images.iloc[i]['filename'])\n",
        "    plt.imshow(img)\n",
        "    plt.title('Noncancer Imgs')\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dqiVZgP8e_rd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "c_images = pp_gt[pp_gt['class'] == 1]\n",
        "nc_images = pp_gt[pp_gt['class'] == 0]\n",
        "\n",
        "sample_c_images = c_images.sample(n=5)\n",
        "sample_nc_images = nc_images.sample(n=5)"
      ],
      "metadata": {
        "id": "V1n85A3QfDmS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#construct training data pipeline w/ RAM loaded images to improve training time\n",
        "\n",
        "pp_gt['filename'] = pp_gt['filename'].apply(lambda x: x.replace(\n",
        "    '/content/drive/MyDrive/dataset/preprocessed_images',\n",
        "    '/content/preprocessed_images_zip/preprocessed_images'))\n",
        "filepaths = pp_gt['filename'].values\n",
        "labels = pp_gt['class'].astype(int).values\n",
        "\n",
        "train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
        "    filepaths, labels, test_size=0.2, stratify=labels, random_state=42)\n",
        "\n",
        "def decode_image(path, label):\n",
        "    image = tf.io.read_file(path)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "    image = tf.image.resize(image, (224, 224))\n",
        "    return image, label\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((train_paths, train_labels))\n",
        "train_ds = train_ds.shuffle(buffer_size=1024) \\\n",
        "                   .map(decode_image, num_parallel_calls=tf.data.AUTOTUNE) \\\n",
        "                   .batch(64) \\\n",
        "                   .prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "val_ds = tf.data.Dataset.from_tensor_slices((val_paths, val_labels))\n",
        "val_ds = val_ds.map(decode_image, num_parallel_calls=tf.data.AUTOTUNE) \\\n",
        "               .batch(64) \\\n",
        "               .prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "GgXi_Rp2fJqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.initializers import GlorotUniform\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "#New model with ResNet50 base and three-layer dense head classifier\n",
        "\n",
        "resnet_model = tf.keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "#freeze all ResNet50 layers\n",
        "for layer in resnet_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "x = layers.GlobalAveragePooling2D()(resnet_model.output)\n",
        "x = layers.Dropout(0.4)(x)\n",
        "x = layers.Dense(128, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "x = layers.Dense(256, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
        "output = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "my_model = models.Model(inputs=resnet_model.input, outputs=output)\n",
        "\n",
        "my_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=.0005),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "VTXXx-d_fQi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_model.fit(\n",
        "    train_ds,\n",
        "    validation_data=(val_ds),\n",
        "    epochs=25,\n",
        ")"
      ],
      "metadata": {
        "id": "bkKMMc0-fUBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#unfreeze deepest 20 ResNet50 layers\n",
        "\n",
        "for layer in my_model.layers[-20:]:\n",
        "  layer.trainable = True\n",
        "\n",
        "my_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=.05),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "_pPVOg6YfV77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_model.fit(\n",
        "    train_ds,\n",
        "    validation_data=(val_ds),\n",
        "    epochs=25,\n",
        ")"
      ],
      "metadata": {
        "id": "utKPYUpgfYMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEoq0k-wEV-2"
      },
      "source": [
        "# Vision Transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 0: Imports and Dataset Download"
      ],
      "metadata": {
        "id": "ylRyeZyXcKRf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8UsEwVmZU2TD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "\n",
        "import timm  # For pretrained models, including Vision Transformer\n",
        "from tqdm import tqdm  # For progress bars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_9iErhUEpIV"
      },
      "outputs": [],
      "source": [
        "# Download the dataset via kagglehub (assumes kagglehub is properly configured)\n",
        "import kagglehub\n",
        "path = kagglehub.dataset_download(\"andrewmvd/isic-2019\")\n",
        "print(\"Path to dataset files:\", path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJb9LOweLH-n"
      },
      "source": [
        "### Step 1: Prepare the Dataset and Labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p53b0DujLMbe"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Define paths to the CSV files and image directory\n",
        "metadata_csv = os.path.join(path, \"ISIC_2019_Training_Metadata.csv\")\n",
        "ground_truth_csv = os.path.join(path, \"ISIC_2019_Training_GroundTruth.csv\")\n",
        "images_dir = os.path.join(path, \"ISIC_2019_Training_Input\", \"ISIC_2019_Training_Input\")\n",
        "\n",
        "# Read the ground truth CSV.\n",
        "labels_df = pd.read_csv(ground_truth_csv)\n",
        "\n",
        "# Create a binary target column \"cancer\":\n",
        "# An image is marked as cancerous (1) if any of the columns \"MEL\", \"BCC\", or \"SCC\" is positive.\n",
        "labels_df[\"cancer\"] = (labels_df[['MEL', 'BCC', 'SCC']].sum(axis=1) > 0).astype(int)\n",
        "\n",
        "# Create a new column for the full image file paths.\n",
        "labels_df[\"file_path\"] = labels_df[\"image\"].apply(lambda x: os.path.join(images_dir, x + \".jpg\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Split the Data into Training, Validation, and Test Sets"
      ],
      "metadata": {
        "id": "UAgTmdQ9cn1R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oOc8AISalYcS"
      },
      "outputs": [],
      "source": [
        "train_val_df, test_df = train_test_split(\n",
        "    labels_df,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=labels_df['cancer']\n",
        ")\n",
        "\n",
        "# Further split the training+validation set into training (90%) and validation (10%).\n",
        "train_df, val_df = train_test_split(\n",
        "    train_val_df,\n",
        "    test_size=0.1,\n",
        "    random_state=42,\n",
        "    stratify=train_val_df['cancer']\n",
        ")\n",
        "\n",
        "print(\"Training set distribution:\")\n",
        "print(train_df['cancer'].value_counts())\n",
        "print(\"\\nValidation set distribution:\")\n",
        "print(val_df['cancer'].value_counts())\n",
        "print(\"\\nTest set distribution:\")\n",
        "print(test_df['cancer'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: Create a custom pytorch dataset"
      ],
      "metadata": {
        "id": "6oxtyKDNcu0u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ISICDataset(Dataset):\n",
        "    def __init__(self, df, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            df (DataFrame): DataFrame with columns \"file_path\" and \"cancer\".\n",
        "            transform: torchvision transforms to apply.\n",
        "        \"\"\"\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        img_path = row[\"file_path\"]\n",
        "        label = int(row[\"cancer\"])\n",
        "\n",
        "        # Load image and convert to RGB\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "lYh67d-Pcw2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YIRoaCGLdih"
      },
      "source": [
        "### Step 4: Define Transforms and DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DBZTjImJLR4k"
      },
      "outputs": [],
      "source": [
        "input_size = 224\n",
        "\n",
        "# Transformations for training (including data augmentation)\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((input_size, input_size)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ToTensor(),\n",
        "    # Normalization using the same statistics as used during model pretraining.\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Transformations for validation and testing (only resize and normalization)\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((input_size, input_size)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = ISICDataset(train_df, transform=train_transform)\n",
        "val_dataset   = ISICDataset(val_df, transform=test_transform)\n",
        "test_dataset  = ISICDataset(test_df, transform=test_transform)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pfuu24A6LvuF"
      },
      "source": [
        "### Step 3: Data class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gs2Ve7jWLzSk"
      },
      "outputs": [],
      "source": [
        "class ISICDataset(Dataset):\n",
        "    def __init__(self, df, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            df (DataFrame): DataFrame with columns \"file_path\" and \"cancer\".\n",
        "            transform: torchvision transforms to apply.\n",
        "        \"\"\"\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        img_path = row[\"file_path\"]\n",
        "        label = int(row[\"cancer\"])\n",
        "\n",
        "        # Open image and convert to RGB\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6UHyixZL4Eo"
      },
      "source": [
        "### Step 4: Transforms + DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hLlQHcDUL90l"
      },
      "outputs": [],
      "source": [
        "input_size = 224\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((input_size, input_size)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ToTensor(),\n",
        "    # Normalization values should match those used during pretraining of the model.\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((input_size, input_size)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "train_dataset = ISICDataset(train_df, transform=train_transform)\n",
        "test_dataset  = ISICDataset(test_df, transform=test_transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHcmQZ3PMJty"
      },
      "source": [
        "### Step 5: Setup the Model, Loss, and Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7_Bn7Uu8MNNA"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Create the Vision Transformer model with pretrained weights.\n",
        "# The model is set to output 2 classes for binary classification.\n",
        "model = timm.create_model('vit_base_patch16_224', pretrained=True, num_classes=2)\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAFp6HG-KNJu"
      },
      "source": [
        "### Step 6: Training Loop (with Validation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bedisjv0KRfO"
      },
      "outputs": [],
      "source": [
        "num_epochs = 5\n",
        "for epoch in range(num_epochs):\n",
        "    # Training\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Training\"):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / len(train_dataset)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {epoch_loss:.4f}\")\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Validation\"):\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (preds == labels).sum().item()\n",
        "\n",
        "    val_acc = 100.0 * correct / total\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Validation Accuracy: {val_acc:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXSKnOffKVtT"
      },
      "source": [
        "### Step 7: Test evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dxgOQTeVKZ6X"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "test_correct = 0\n",
        "test_total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in tqdm(test_loader, desc=\"Testing\"):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        test_total += labels.size(0)\n",
        "        test_correct += (preds == labels).sum().item()\n",
        "\n",
        "test_acc = 100.0 * test_correct / test_total\n",
        "print(f\"Final Test Accuracy: {test_acc:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDWUQUn7KerS"
      },
      "source": [
        "### Save Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vz4LQGFFKf48"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"vit_isic_finetuned.pth\")\n",
        "print(\"Model saved as vit_isic_finetuned.pth\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}